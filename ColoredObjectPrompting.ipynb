{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a2732a-d5a8-4c4a-b483-32bf97756ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 804 ms, sys: 133 ms, total: 936 ms\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pal\n",
    "import json\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "from pal.prompt import math_prompts, colored_object_prompt, penguin_prompt, date_understanding_prompt, algorithmic_prompt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ad9766-7ee0-4fbf-9851-9bca5e1007ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Color Object  Position\n",
      "2   Red    Cup         3\n",
      "Cyan\n"
     ]
    }
   ],
   "source": [
    "data = {\"Color\": [\"Cyan\", \"Green\", \"Red\", \"Grey\"], \"Object\": [\"Phone\", \"Apple\", \"Cup\", \"Lamp\"], \"Position\": [1, 2, 3, 4]}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.query('Object == \"Cup\"'))\n",
    "print(df[\"Color\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2a19d7-9c20-48ff-b5ff-71ba0c90c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "You are a helpful assistant that accurately solves reasoning questions about colored objects by acting as an agent who will perform Thoughts, where you will perform logical reasoning, and Actions, which perform functions and operations.\n",
      "\n",
      "USER\n",
      "Whenever you synthesize information and perform reasoning, it is a Thought. When you need to perform an operation on a table, it is an Action. There are 7 types of actions: \n",
      "(1) CREATE_START[data]CREATE_END: CREATE takes a data definition of a table which will be used to generate a pandas dataframe, so make sure that the input does not contain anything unnecessary for the pandas dataframe input generation. Write the data in json format.\n",
      "(2) GET_VALUE_START[row_number;column]GET_VALUE_END: GET_VALUE takes the row_number, e.g., 0 is the 1st row of the table, and the name of a column, e.g., age, and returns the value of the cell, e.g., the age in the first row of the table.\n",
      "(3) FIND_START[query]FIND_END: FIND takes a query, similarly to COUNT, and returns the entries in the table that satisfies the query. For example, FIND_START[height < 13]FIND_END would return the entries whose value in the column \"height\" is less than 13. IMPORTANT: This will not change the entries of the table. \n",
      "(4) FILTER_START[query]FILTER_END: FILTER takes a query, similarly to FIND, but instead changes the table such that only entries that satisfy the query are preserved. For example, FILTER_START[age < 18]FILTER_END would alter the table so that only entries whose value in the column \"age\" is less than 18 would be preserved. IMPORTANT: This DOES change the table.\n",
      "(5) ADD_START[row]ADD_END: ADD takes a row and adds it to the table. Write the data in json format. NOTE: This does not necessarily preserve any previous sorted order.\n",
      "(6) SUM_START[column]SUM_END: SUM takes a column and takes the sum of all the elements in that column. For example, SUM_START[age]SUM_END would sum all the values in the column \"age\". \n",
      "(7) FINISH_START[answer]FINISH_END: When you finish the question, write your answer as FINISH_START[answer]FINISH_END and terminate your response.\n",
      "Terminate your response after an action. Then, an Observation is returned by the user. IMPORTANT: YOU DO NOT WRITE OBSERVATIONS. THEY WILL BE PROVIDED TO YOU. You will be given a question and you will perform Thoughts and Actions until you get the answer. When you get the answer, you will perform the Action called FINISH. While you are reasoning out solutions, you will continually refer back to relevant portions of the question and employ logical reasoning to determine your next action. Ensure all the inputs to your actions are perfectly accurate.\n",
      "\n",
      "Question: On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, and a mauve fidget spinner. What is the color of the object directly to the right of the stress ball?\n",
      "\n",
      "ASSISTANT\n",
      "Thought: First, I need to create a table containing the colors of the objects, the names of the objects, and their positions on the table.\n",
      "Action: CREATE_START[{\"Color\": [\"Purple\", \"Pink\", \"Brown\", \"Green\", \"Mauve\"], \"Name\": [\"Paperclip\", \"Stress Ball\", \"Keychain\", \"Scrunchiephone Charger\", \"Fidget Spinner\"], \"Position\": [1, 2, 3, 4, 5]}]CREATE_END\n",
      "\n",
      "USER\n",
      "Observation: Created table\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Now I first need to find which position the Stress Ball is in. I can do this by finding the entry with that name. I will use the FIND action to avoid changing the table.\n",
      "Action: FIND_START[Name == 'Stress Ball']FIND_END\n",
      "\n",
      "USER\n",
      "Observation: Found results:\n",
      "Color         Name  Position\n",
      "0  Pink  Stress Ball         2\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Therefore, the position of the Stress Ball is 2. Thus, the position of the object to the right of it is 3. To get the color, I can find the entry with that position. I will use the FIND action to avoid changing the table..\n",
      "Action: FIND_START[Position == 3]FIND_END\n",
      "\n",
      "USER\n",
      "Observation: Found results:\n",
      "Color      Name  Position\n",
      "0  Brown  Keychain         3\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Thus, the color is Brown.\n",
      "Action: FINISH_START[Brown]FINISH_END\n",
      "\n",
      "USER\n",
      "Question: There are 2 green apples, 3 red phones, 1 green phone, 8 green cups, 1 pink phone, and 2 red cups. If I remove all the green items, how many phones are left?\n",
      "\n",
      "ASSISTANT\n",
      "Thought: First, I need to create a table containing the colors of the objects, the names of the objects, and how many times they appear.\n",
      "Action: CREATE_START[{\"Color\": [\"green\", \"red\", \"green\", \"green\", \"pink\", \"red\"], \"Object\": [\"apple\", \"phone\", \"phone\", \"cup\", \"phone\", \"cup\"], \"Count\": [2, 3, 1, 8, 1, 2]}]CREATE_END\n",
      "\n",
      "USER\n",
      "Observation: Created table\n",
      "\n",
      "ASSISTANT\n",
      "Thought: I first need to remove all the green items, so I will use the FILTER action.\n",
      "Action: FILTER_START[Color != \"green\"]FILTER_END\n",
      "\n",
      "USER\n",
      "Observation: Changed the table to:\n",
      "  Color Object  Count\n",
      "1   red  phone      3\n",
      "4  pink  phone      1\n",
      "5   red    cup      2\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Now to find the number of phones, I first remove all items that aren't phones. To do this, I will use the FILTER action.\n",
      "Action: FILTER_START[Object == \"phone\"]FILTER_END\n",
      "\n",
      "USER\n",
      "Observation: Changed the table to:\n",
      "  Color Object  Count\n",
      "1   red  phone      3\n",
      "4  pink  phone      1\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Finally, to get the number of phones left, I take the sum of the Count column.\n",
      "Action: SUM_START[Count]SUM_END\n",
      "\n",
      "USER\n",
      "Observation: 4\n",
      "\n",
      "ASSISTANT\n",
      "Thought: Therefore, there are 4 phones left.\n",
      "Action: FINISH_START[4]FINISH_END\n",
      "\n",
      "USER\n",
      "Question: There is a cyan phone, a green apple, a red cup, and a grey lamp on the table in that order. What is the color of the item furthest from the cup?\n",
      "\n",
      "ASSISTANT\n",
      "Thought: I first need to create the table.\n",
      "Action: CREATE_START[{\"Color\": [\"Cyan\", \"Green\", \"Red\", \"Grey\"], \"Object\": [\"Phone\", \"Apple\", \"Cup\", \"Lamp\"], \"Position\": [1, 2, 3, 4]}]CREATE_END\n",
      "\n",
      "USER\n",
      "Observation: Created table\n",
      "\n",
      "ASSISTANT\n",
      "Thought: I first need to find the position of the cup.\n",
      "Action: FIND_START[Object == \"Cup\"]FIND_END\n",
      "\n",
      "USER\n",
      "Observation: Found results\n",
      "  Color Object  Position\n",
      "2   Red    Cup         3\n",
      "\n",
      "ASSISTANT\n",
      "Thought: So the position of the cup is 3. The positions at the endpoints are 1 and 4. Now 4-3=1, while 3-1=2 and since 2>1, the item furthest from the cup is in position 1. I therefore need to find the color of the item in position 1.\n",
      "Action: GET_VALUE_START[0;Color]GET_VALUE_END\n",
      "\n",
      "USER\n",
      "Observation: Cyan\n",
      "\n",
      "ASSISTANT\n",
      "Thought: So the color of the object furthest from the cup is cyan.\n",
      "Action: FINISH_START[Cyan]FINISH_END\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Whenever you synthesize information and perform reasoning, it is a Thought. When you need to perform an operation on a table, it is an Action. There are 7 types of actions: \n",
    "(1) CREATE_START[data]CREATE_END: CREATE takes a data definition of a table which will be used to generate a pandas dataframe, so make sure that the input does not contain anything unnecessary for the pandas dataframe input generation. Write the data in json format.\n",
    "(2) GET_VALUE_START[row_number;column]GET_VALUE_END: GET_VALUE takes the row_number, e.g., 0 is the 1st row of the table, and the name of a column, e.g., age, and returns the value of the cell, e.g., the age in the first row of the table.\n",
    "(3) FIND_START[query]FIND_END: FIND takes a query, similarly to COUNT, and returns the entries in the table that satisfies the query. For example, FIND_START[height < 13]FIND_END would return the entries whose value in the column \"height\" is less than 13. IMPORTANT: This will not change the entries of the table. \n",
    "(4) FILTER_START[query]FILTER_END: FILTER takes a query, similarly to FIND, but instead changes the table such that only entries that satisfy the query are preserved. For example, FILTER_START[age < 18]FILTER_END would alter the table so that only entries whose value in the column \"age\" is less than 18 would be preserved. IMPORTANT: This DOES change the table.\n",
    "(5) ADD_START[row]ADD_END: ADD takes a row and adds it to the table. Write the data in json format. NOTE: This does not necessarily preserve any previous sorted order.\n",
    "(6) SUM_START[column]SUM_END: SUM takes a column and takes the sum of all the elements in that column. For example, SUM_START[age]SUM_END would sum all the values in the column \"age\". \n",
    "(7) FINISH_START[answer]FINISH_END: When you finish the question, write your answer as FINISH_START[answer]FINISH_END and terminate your response.\n",
    "Terminate your response after an action. Then, an Observation is returned by the user. IMPORTANT: YOU DO NOT WRITE OBSERVATIONS. THEY WILL BE PROVIDED TO YOU. You will be given a question and you will perform Thoughts and Actions until you get the answer. When you get the answer, you will perform the Action called FINISH. While you are reasoning out solutions, you will continually refer back to relevant portions of the question and employ logical reasoning to determine your next action. Ensure all the inputs to your actions are perfectly accurate.\n",
    "\"\"\"\n",
    "color_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that accurately solves reasoning questions about colored objects by acting as an agent who will perform Thoughts, where you will perform logical reasoning, and Actions, which perform functions and operations.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt + '\\n' + \"\"\"Question: On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, and a mauve fidget spinner. What is the color of the object directly to the right of the stress ball?\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: First, I need to create a table containing the colors of the objects, the names of the objects, and their positions on the table.\n",
    "Action: CREATE_START[{\"Color\": [\"Purple\", \"Pink\", \"Brown\", \"Green\", \"Mauve\"], \"Name\": [\"Paperclip\", \"Stress Ball\", \"Keychain\", \"Scrunchiephone Charger\", \"Fidget Spinner\"], \"Position\": [1, 2, 3, 4, 5]}]CREATE_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Observation: Created table\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Now I first need to find which position the Stress Ball is in. I can do this by finding the entry with that name. I will use the FIND action to avoid changing the table.\n",
    "Action: FIND_START[Name == 'Stress Ball']FIND_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Found results:\n",
    "Color         Name  Position\n",
    "0  Pink  Stress Ball         2\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Therefore, the position of the Stress Ball is 2. Thus, the position of the object to the right of it is 3. To get the color, I can find the entry with that position. I will use the FIND action to avoid changing the table..\n",
    "Action: FIND_START[Position == 3]FIND_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Found results:\n",
    "Color      Name  Position\n",
    "0  Brown  Keychain         3\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Thus, the color is Brown.\n",
    "Action: FINISH_START[Brown]FINISH_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Question: There are 2 green apples, 3 red phones, 1 green phone, 8 green cups, 1 pink phone, and 2 red cups. If I remove all the green items, how many phones are left?\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: First, I need to create a table containing the colors of the objects, the names of the objects, and how many times they appear.\n",
    "Action: CREATE_START[{\"Color\": [\"green\", \"red\", \"green\", \"green\", \"pink\", \"red\"], \"Object\": [\"apple\", \"phone\", \"phone\", \"cup\", \"phone\", \"cup\"], \"Count\": [2, 3, 1, 8, 1, 2]}]CREATE_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Created table\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: I first need to remove all the green items, so I will use the FILTER action.\n",
    "Action: FILTER_START[Color != \"green\"]FILTER_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Changed the table to:\n",
    "  Color Object  Count\n",
    "1   red  phone      3\n",
    "4  pink  phone      1\n",
    "5   red    cup      2\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Now to find the number of phones, I first remove all items that aren't phones. To do this, I will use the FILTER action.\n",
    "Action: FILTER_START[Object == \"phone\"]FILTER_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Changed the table to:\n",
    "  Color Object  Count\n",
    "1   red  phone      3\n",
    "4  pink  phone      1\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Finally, to get the number of phones left, I take the sum of the Count column.\n",
    "Action: SUM_START[Count]SUM_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: 4\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: Therefore, there are 4 phones left.\n",
    "Action: FINISH_START[4]FINISH_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Question: There is a cyan phone, a green apple, a red cup, and a grey lamp on the table in that order. What is the color of the item furthest from the cup?\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: I first need to create the table.\n",
    "Action: CREATE_START[{\"Color\": [\"Cyan\", \"Green\", \"Red\", \"Grey\"], \"Object\": [\"Phone\", \"Apple\", \"Cup\", \"Lamp\"], \"Position\": [1, 2, 3, 4]}]CREATE_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Created table\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: I first need to find the position of the cup.\n",
    "Action: FIND_START[Object == \"Cup\"]FIND_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Found results\n",
    "  Color Object  Position\n",
    "2   Red    Cup         3\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: So the position of the cup is 3. The positions at the endpoints are 1 and 4. Now 4-3=1, while 3-1=2 and since 2>1, the item furthest from the cup is in position 1. I therefore need to find the color of the item in position 1.\n",
    "Action: GET_VALUE_START[0;Color]GET_VALUE_END\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Observation: Cyan\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"Thought: So the color of the object furthest from the cup is cyan.\n",
    "Action: FINISH_START[Cyan]FINISH_END\"\"\"}\n",
    "]\n",
    "for message in color_messages:\n",
    "    print(message[\"role\"].upper())\n",
    "    print(message[\"content\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c077dc1-b1a9-4ffc-b47a-27c896f3295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 1872, 593, 658, 852, 1300, 130, 1554, 1293, 924, 923, 284, 1858, 1187, 1745, 1889, 1388, 942, 1825, 570, 1154, 802, 415, 361, 1733, 88, 782, 1522, 102, 1195, 1987, 13, 1891, 1869, 512, 1447, 1221, 73, 1312, 1203, 454, 1120, 1442, 1375, 872, 848, 1399, 1614, 1567, 385, 1180, 624, 476, 464, 822, 655, 66, 503, 406, 182, 203, 1517, 417, 147, 1572, 1925, 855, 172, 1555, 1011, 108, 1756, 1428, 1603, 1140, 1496, 1766, 1188, 432, 819, 301, 1881, 1659, 1647, 785, 1008, 820, 1640, 1270, 1119, 1507, 727, 63, 1576, 1511, 563, 1333, 1845, 561, 91]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620e66b96f1d413ea7946a132113894b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through Colored Object questions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/git/pal/pal/core/backend.py:70\u001b[0m, in \u001b[0;36mcall_gpt_history\u001b[0;34m(messages, model, stop, temperature, top_p, max_tokens, majority_at)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     ans \u001b[38;5;241m=\u001b[39m chat_api_history(\n\u001b[1;32m     71\u001b[0m                 model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     72\u001b[0m                 max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[1;32m     73\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m     74\u001b[0m                 messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     75\u001b[0m                 temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     76\u001b[0m                 top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m     77\u001b[0m                 n\u001b[38;5;241m=\u001b[39mrequested_completions,\n\u001b[1;32m     78\u001b[0m                 best_of\u001b[38;5;241m=\u001b[39mrequested_completions)\n\u001b[1;32m     79\u001b[0m completions\u001b[38;5;241m.\u001b[39mextend(ans)\n",
      "File \u001b[0;32m~/git/pal/pal/core/backend.py:115\u001b[0m, in \u001b[0;36mchat_api_history\u001b[0;34m(model, max_tokens, stop, messages, temperature, top_p, n, best_of)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_api_history\u001b[39m(model, max_tokens, stop, messages, temperature,\n\u001b[1;32m    114\u001b[0m             top_p, n, best_of):\n\u001b[0;32m--> 115\u001b[0m     ans \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    116\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    117\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[1;32m    118\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    119\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    120\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    121\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m    122\u001b[0m         n\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m ans\u001b[38;5;241m.\u001b[39mchoices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    649\u001b[0m             {\n\u001b[1;32m    650\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    651\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    652\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    659\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    665\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    666\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    667\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    668\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    669\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    670\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    673\u001b[0m             },\n\u001b[1;32m    674\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    675\u001b[0m         ),\n\u001b[1;32m    676\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    677\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    678\u001b[0m         ),\n\u001b[1;32m    679\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    680\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    681\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    682\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m )\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    943\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    944\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    945\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    946\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    947\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    948\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    979\u001b[0m         request,\n\u001b[1;32m    980\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     40\u001b[0m numIters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 41\u001b[0m gens \u001b[38;5;241m=\u001b[39m interface\u001b[38;5;241m.\u001b[39mgenerate_history(messages\u001b[38;5;241m=\u001b[39mmessages, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m gens[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#print(output)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/pal/pal/core/interface.py:109\u001b[0m, in \u001b[0;36mProgramInterface.generate_history\u001b[0;34m(self, messages, temperature, top_p, max_tokens, majority_at)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_history\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: \u001b[38;5;28mlist\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, top_p: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \n\u001b[1;32m    108\u001b[0m         max_tokens: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, majority_at: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ):\n\u001b[0;32m--> 109\u001b[0m     gens \u001b[38;5;241m=\u001b[39m call_gpt_history(messages, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, \n\u001b[1;32m    110\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature, top_p\u001b[38;5;241m=\u001b[39mtop_p, max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens, majority_at\u001b[38;5;241m=\u001b[39mmajority_at, )\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mprint\u001b[39m(gens)\n",
      "File \u001b[0;32m~/git/pal/pal/core/backend.py:82\u001b[0m, in \u001b[0;36mcall_gpt_history\u001b[0;34m(messages, model, stop, temperature, top_p, max_tokens, majority_at)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completions) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_completions:\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m completions[:num_completions]\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mRateLimitError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to call GPT API\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'error'"
     ]
    }
   ],
   "source": [
    "interface = pal.interface.ProgramInterface(\n",
    "  model='gpt-4o-mini',\n",
    "  stop='\\n\\n\\n', # stop generation str for Codex API\n",
    "  get_answer_expr='solution()' # python expression evaluated after generated code to obtain answer \n",
    ")\n",
    "\n",
    "\n",
    "json_list = None\n",
    "max_count = 100\n",
    "counter = 0\n",
    "responses = []\n",
    "with open('datasets/reasoning_about_colored_objects.json', 'r') as json_file:\n",
    "    json_list = json.load(json_file)\n",
    "json_list = json_list[\"examples\"]\n",
    "jsonSamples = random.sample(range(0, len(json_list)), max_count)\n",
    "print(jsonSamples)\n",
    "#jsonSamples = [819, 1000, 699, 749, 580, 366, 1275, 203, 492, 773]\n",
    "#jsonSamples = [269, 436, 836, 1291, 1283, 712, 391, 474, 1164, 783]\n",
    "#jsonSamples = [1719, 612, 1997, 744, 1984, 1693, 1734, 767, 359, 1320]\n",
    "for json_pos in tqdm(jsonSamples, desc=\"Going through Colored Object questions\"):\n",
    "    result = json_list[json_pos]\n",
    "    question = result[\"input\"]\n",
    "    target = result[\"target_scores\"]\n",
    "    curResponse = {\"question\": question, \"target\": target}\n",
    "    messages = []\n",
    "    for message in color_messages:\n",
    "        messages.append(message)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt + '\\n' + \"Question: \" + question})\n",
    "    finished = False\n",
    "    curTable = None\n",
    "    numIters = 0\n",
    "    maxIters = 20\n",
    "    while not finished:\n",
    "        if numIters >= maxIters:\n",
    "            print(json_pos)\n",
    "            print(\"Maximum number of iterations reached\")\n",
    "            print(\"##################################\\n\")\n",
    "            curResponse[\"received\"] = -987654321\n",
    "            break\n",
    "        numIters += 1\n",
    "        gens = interface.generate_history(messages=messages, max_tokens=1024)\n",
    "        output = gens[0]\n",
    "        #print(output)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": output})\n",
    "        curAction = output[output.find(\"Action: \") + len(\"Action: \"):]\n",
    "        #print(\"Action: \" + curAction)\n",
    "        if \"finish\" in curAction.lower():\n",
    "            finished = True\n",
    "            expression = curAction[curAction.find(\"FINISH_START[\") + len(\"FINISH_START[\"):curAction.find(\"]FINISH_END\")]\n",
    "            curResponse[\"received\"] = expression.lower()\n",
    "            #print(expression)\n",
    "        else:\n",
    "            evaled = None\n",
    "            expression = None\n",
    "            if \"CREATE\" in curAction:\n",
    "                expression = curAction[curAction.find(\"CREATE_START[\") + len(\"CREATE_START[\"):curAction.find(\"]CREATE_END\")]\n",
    "                try:\n",
    "                    data = json.loads(expression)\n",
    "                    curTable = pd.DataFrame(data)\n",
    "                    evaled = \"Created table\"\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid input. This was the exception: {e}. Try again. \"\n",
    "                #print(curTable)\n",
    "            elif \"COUNT\" in curAction:\n",
    "                expression = curAction[curAction.find(\"COUNT_START[\") + len(\"COUNT_START[\"):curAction.find(\"]COUNT_END\")]\n",
    "                try:\n",
    "                    evaled = str(len(curTable.query(expression)))\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid query. This was the exception: {e}. It is possible that (1) The table does not exist yet. (2) The query is invalid.\"\n",
    "            elif \"FIND\" in curAction:\n",
    "                expression = curAction[curAction.find(\"FIND_START[\") + len(\"FIND_START[\"):curAction.find(\"]FIND_END\")]\n",
    "                try:\n",
    "                    evaled = \"Found results:\\n\"\n",
    "                    evaled += curTable.query(expression).reset_index(drop=True).to_string()\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid query. This was the exception: {e}. It is possible that (1) The table does not exist yet. (2) The query is invalid.\"\n",
    "            elif \"FILTER\" in curAction:\n",
    "                expression = curAction[curAction.find(\"FILTER_START[\") + len(\"FILTER_START[\"):curAction.find(\"]FILTER_END\")]\n",
    "                try:\n",
    "                    curTable = curTable.query(expression)\n",
    "                    curTable = curTable.reset_index(drop=True)\n",
    "                    evaled = \"Changed the table to:\\n\"\n",
    "                    evaled += curTable.to_string()\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid query. This was the exception: {e}. It is possible that (1) The table does not exist yet. (2) The query is invalid.\"\n",
    "            elif \"GET_VALUE\" in curAction:\n",
    "                expression = curAction[curAction.find(\"GET_VALUE_START[\") + len(\"GET_VALUE_START[\"):curAction.find(\"]GET_VALUE_END\")]\n",
    "                expression = expression.split(';')\n",
    "                expression[0] = int(expression[0])\n",
    "                try:\n",
    "                    evaled = str(curTable[expression[1]][expression[0]])\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid input. This was the exception: {e}. It is possible that (1) The table does not exist yet. (2) The column name is wrong.\"\n",
    "            elif \"ADD\" in curAction:\n",
    "                expression = curAction[curAction.find(\"ADD_START[\") + len(\"ADD_START[\"):curAction.find(\"]ADD_END\")]\n",
    "                try:\n",
    "                    row = json.loads(expression)\n",
    "                    new_row = pd.Series(row)\n",
    "                    curTable = pd.concat([curTable, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                    evaled = \"Added row.\"\n",
    "                except Exception as e:\n",
    "                    evaled = f\"That was not a valid input. This was the exception: {e}. Try again.\"\n",
    "            elif \"SUM\" in curAction:\n",
    "                column = curAction[curAction.find(\"SUM_START[\") + len(\"SUM_START[\"):curAction.find(\"]SUM_END\")]\n",
    "                if column in curTable.columns:\n",
    "                    try:\n",
    "                        evaled = str(curTable[column].sum())\n",
    "                    except Exception as e:\n",
    "                        evaled = f\"That was not a valid input. This was the exception: {e}. Try again.\"\n",
    "                else:\n",
    "                    evaled = f\"Column '{column}' does not exist in the table.\"\n",
    "            else:\n",
    "                evaled = \"That was not a valid action. Please input a valid one.\"\n",
    "            #print(\"Expression: \", end = \"\")\n",
    "            #print(expression)\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Observation: \" + evaled})\n",
    "            #print(\"Evaluation: \", end=\"\")\n",
    "            #print(evaled)\n",
    "            #print(messages[-1][\"content\"])\n",
    "    curResponse[\"messages\"] = messages\n",
    "    responses.append(curResponse)\n",
    "numCorrect = 0\n",
    "for response in responses:\n",
    "    if (\"received\" in response.keys()) and (response[\"received\"] in response[\"target\"].keys()) and (response[\"target\"][response[\"received\"]] == 1):\n",
    "        numCorrect += 1\n",
    "    #else:\n",
    "        #print(\"Received: \" + response[\"received\"])\n",
    "        #print(\"Target: \", end=\"\")\n",
    "        #print(response[\"target\"])\n",
    "        #for message in response[\"messages\"][len(color_messages):]:\n",
    "        #    print(message[\"content\"])\n",
    "        #print(\"\")\n",
    "print(\"Number correct = \" + str(numCorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2960e589-57f6-4bb8-82c8-45e2b74cac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "numCorrect = 0\n",
    "for response in responses:\n",
    "    if (response[\"received\"] in response[\"target\"].keys()) and (response[\"target\"][response[\"received\"]] == 1):\n",
    "        numCorrect += 1\n",
    "print(numCorrect)\n",
    "print(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad08ad7b-7fd2-40f9-8ad3-a55d5d236495",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coloredobject-prompting-01-results-gpt-4o-mini.json', 'w') as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b4744-2cab-4416-a84a-48a511a31d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
